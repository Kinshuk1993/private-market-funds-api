# Future Enhancements

## Table of Contents

1. [Evaluation Criteria â€” Current Status](#evaluation-criteria--current-status)
2. [Test Coverage Improvements](#test-coverage-improvements)
3. [Code Quality & Static Analysis](#code-quality--static-analysis)
4. [Concurrency & Multi-Threading](#concurrency--multi-threading)
5. [Dockerfile Improvements](#dockerfile-improvements)
6. [CI/CD Pipeline â€” GitHub Actions](#cicd-pipeline--github-actions)
7. [Database & Data Layer](#database--data-layer)
8. [API & Feature Enhancements](#api--feature-enhancements)
9. [Observability & Monitoring](#observability--monitoring)
10. [Security Hardening](#security-hardening)

---

## Evaluation Criteria â€” Current Status

Every core and bonus criterion from the task specification is **fully met**.

| Criterion | Status | Evidence |
| --------- | ------ | -------- |
| **Functionality** â€” All 8 endpoints | âœ… Met | `GET/POST /funds`, `PUT /funds`, `GET /funds/{id}`, `GET/POST /investors`, `GET/POST /funds/{fund_id}/investments` |
| **Data integrity** â€” DB relationships & constraints | âœ… Met | FK with `RESTRICT`, unique email, 6 `CHECK` constraints, native PG ENUMs, composite index |
| **Code quality** â€” Clean, readable, well-organized | âœ… Met | Router â†’ Service â†’ Repository â†’ Model architecture, SOLID principles, DRY via `BaseRepository` and shared schemas |
| **Documentation** â€” Clear setup instructions | âœ… Met | 10 docs: API Reference, API Examples, Edge Cases, Design Decisions, Database Design, 3Ã— Setup guides, Testing Guide, Code Quality |
| **Error handling** â€” Graceful invalid-request handling | âœ… Met | Domain exceptions (`NotFoundException`, `ConflictException`, `BusinessRuleViolation`), global handlers, consistent JSON envelope, 404/409/422/503 |
| **Testing** (bonus) â€” Unit or integration tests | âœ… Met | 160 pytest unit tests, ~91% coverage, `fail_under=85` enforced |
| **Best practices** (bonus) â€” REST conventions, HTTP codes | âœ… Met | 201 for creates, nouns as resources, nested routes, pagination, CORS, GZip, request tracing, circuit breaker |

### Minor Gaps (not failures)

| Gap | Impact | Why it's acceptable |
| --- | ------ | ------------------- |
| **No Alembic migrations** â€” tables auto-created via `create_all` | Medium | `alembic` is a dependency but not configured. Acceptable for a take-home; required for production schema evolution. |
| **Repository layer at ~27% direct coverage** | Low | Tested implicitly through service-layer mocks and shell-script E2E tests. Dedicated SQLite integration tests would add confidence. |
| **`PUT /funds` with id-in-body** | None | Follows the API spec exactly. Documented as a deliberate design decision. Idiomatic REST would use `PUT /funds/{id}`. |

---

## Test Coverage Improvements

Current: **160 tests, ~91% line coverage, `fail_under=85`**.

### 1. Repository Integration Tests (biggest coverage gap)

`BaseRepository` sits at ~27% direct coverage because services are tested with
mocked repos. Adding integration tests against an in-memory SQLite database
would validate actual SQL, constraint enforcement, and error paths.

```python
# tests/test_fund_repo_integration.py (proposed)
@pytest.fixture
async def sqlite_session():
    """Spin up an async SQLite engine per test."""
    engine = create_async_engine("sqlite+aiosqlite://", echo=False)
    async with engine.begin() as conn:
        await conn.run_sync(SQLModel.metadata.create_all)
    async with AsyncSession(engine) as session:
        yield session
    await engine.dispose()

async def test_create_and_get_fund(sqlite_session):
    repo = FundRepository(sqlite_session)
    created = await repo.create(Fund(name="Test", ...))
    fetched = await repo.get(created.id)
    assert fetched.name == "Test"
```

### 2. End-to-End Pytest Tests

The current E2E coverage lives in shell scripts (`test_docker.sh`,
`test_local.sh`, `test_no_db.sh`). Moving them into pytest with
`httpx.AsyncClient` and an actual SQLite backend would:

- Unify test reporting (single `pytest` run)
- Enable coverage measurement for router and startup code
- Make CI simpler (one test command instead of shell + curl)

### 3. Mocking Strategy Refinements

| Technique | Where to apply |
| --------- | -------------- |
| `unittest.mock.patch` for env vars | `test_config.py` â€” test `USE_SQLITE`, `DEBUG`, connection string assembly |
| `respx` or `httpx.MockTransport` | If external HTTP calls are added in future |
| `freezegun` or `time_machine` | Cache TTL expiration tests â€” replace `time.time()` patching with deterministic clock |
| `factory_boy` with SQLModel | Replace hand-rolled `make_fund()` helpers for richer object graphs |

### 4. Mutation Testing

[`mutmut`](https://github.com/boxed/mutmut) or
[`cosmic-ray`](https://github.com/sixty-north/cosmic-ray) would verify that
tests actually *catch* bugs, not just execute code. High line coverage does not
guarantee high fault detection.

```bash
pip install mutmut
mutmut run --paths-to-mutate=app/services/
```

### 5. Property-Based Testing

[`hypothesis`](https://hypothesis.readthedocs.io/) can generate hundreds of
random schema inputs automatically:

```python
from hypothesis import given, strategies as st

@given(year=st.integers(min_value=1900, max_value=2031))
def test_vintage_year_always_valid(year):
    fund = FundCreate(name="Fund", vintage_year=year, target_size_usd=Decimal("1000"))
    assert 1900 <= fund.vintage_year <= 2031
```

---

## Code Quality & Static Analysis

### 1. Add Cyclomatic Complexity Checking

[`radon`](https://radon.readthedocs.io/) measures cyclomatic complexity per
function. [`flake8-cognitive-complexity`](https://github.com/Melevir/flake8-cognitive-complexity)
integrates directly into the existing flake8 pipeline.

```bash
# Install
pip install radon flake8-cognitive-complexity

# Standalone report â€” flag anything above grade B (complexity > 5)
radon cc app/ -s -n B

# Or add to setup.cfg for automatic enforcement
# [flake8]
# max-cognitive-complexity = 7
```

Current hotspots likely to score highest:

- `investment_service.create_investment` (multiple validation branches)
- `resilience.CircuitBreaker.__call__` (state machine with 3 states)
- `cache.TTLCache.get` (expiry + eviction logic)

### 2. Type Checking with mypy

Add strict type checking to catch bugs before runtime:

```bash
pip install mypy types-sqlalchemy
mypy app/ --strict --ignore-missing-imports
```

Configuration in `pyproject.toml`:

```toml
[tool.mypy]
python_version = "3.12"
strict = true
warn_return_any = true
warn_unused_configs = true
plugins = ["pydantic.mypy", "sqlalchemy.ext.mypy.plugin"]
```

### 3. Security Linting with Bandit

[`bandit`](https://bandit.readthedocs.io/) scans for common security pitfalls
(hardcoded passwords, SQL injection, unsafe deserialization):

```bash
pip install bandit
bandit -r app/ -c pyproject.toml
```

### 4. Dependency Vulnerability Scanning

```bash
pip install pip-audit safety
pip-audit                    # Check installed packages against PyPI advisory DB
safety check                 # Check against Safety's vulnerability database
```

### 5. Pre-Commit Hooks

Enforce all checks locally before code reaches CI:

```yaml
# .pre-commit-config.yaml
repos:
  - repo: https://github.com/psf/black
    rev: 24.10.0
    hooks: [{ id: black }]
  - repo: https://github.com/pycqa/isort
    rev: 5.13.2
    hooks: [{ id: isort }]
  - repo: https://github.com/pycqa/flake8
    rev: 7.1.1
    hooks: [{ id: flake8 }]
  - repo: https://github.com/pre-commit/mirrors-mypy
    rev: v1.13.0
    hooks: [{ id: mypy, additional_dependencies: [pydantic, sqlalchemy[mypy]] }]
```

---

## Concurrency & Multi-Threading

### Current State

The service already handles concurrency well at the I/O level:

- **`asyncio` + `asyncpg`** â€” non-blocking DB calls; a single event loop
  serves thousands of concurrent requests without thread overhead.
- **Connection pooling** â€” `pool_size=10`, `max_overflow=20`, `pool_pre_ping=True`.
- **TOCTOU race protection** â€” duplicate-email detection catches `IntegrityError`
  from the DB unique constraint after the pre-check SELECT.

### Improvements

| Enhancement | Description |
| ----------- | ----------- |
| **Gunicorn + Uvicorn workers** | Run `gunicorn -k uvicorn.workers.UvicornWorker -w 4` to use multiple CPU cores. Currently the Dockerfile runs a single Uvicorn worker. |
| **`asyncio.TaskGroup`** | For endpoints that need parallel DB queries (e.g., fetching fund + investor in `create_investment`), use `TaskGroup` to run them concurrently instead of sequentially. |
| **Optimistic concurrency control** | Add a `version` column to `funds` and use `WHERE id = :id AND version = :v` in UPDATE statements to detect and reject conflicting writes (prevents lost-update problem). |
| **Read replicas** | Route read queries (`GET /funds`, `GET /investors`) to a read replica; writes to the primary. SQLAlchemy supports this via `Session(bind=...)` routing. |
| **Rate limiting** | Add `slowapi` or a custom middleware to throttle requests per IP/API-key, protecting against abuse and thundering-herd scenarios. |
| **Distributed cache** | Replace the in-memory `TTLCache` with Redis for multi-instance deployments. The current cache is per-process and doesn't survive restarts or scale across replicas. |
| **Background tasks** | Use FastAPI `BackgroundTasks` or Celery for expensive operations (e.g., sending email confirmations, generating PDF reports) without blocking the response. |

### Worker Scaling â€” Dockerfile Change

```dockerfile
# Current (single worker):
CMD ["uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]

# Improved (multi-worker via Gunicorn):
CMD ["gunicorn", "app.main:app", \
     "-k", "uvicorn.workers.UvicornWorker", \
     "-w", "4", \
     "-b", "0.0.0.0:8000", \
     "--access-logfile", "-"]
```

---

## Dockerfile Improvements

### Dockerfile Current State

The Dockerfile is already well-structured: multi-stage build, non-root user,
slim base image, `.dockerignore`-friendly layout.

### Dockerfile Future Improvements

| Enhancement | Benefit |
| ----------- | ------- |
| **Pin exact base image digest** | `FROM python:3.14-slim@sha256:abc...` ensures reproducible builds. Tag-only (`3.14-slim`) can silently change. |
| **Add `HEALTHCHECK` instruction** | `HEALTHCHECK CMD curl -f http://localhost:8000/health \|\| exit 1` â€” enables Docker and orchestrators to detect unhealthy containers automatically. |
| **Gunicorn multi-worker CMD** | See [Concurrency section](#concurrency--multi-threading) â€” use Gunicorn with Uvicorn workers for CPU utilization. |
| **Distroless / Alpine runtime** | Switch runtime stage from `python:3.14-slim` to `gcr.io/distroless/python3` or `python:3.14-alpine` for a smaller attack surface (~30 MB vs ~150 MB). |
| **Build-time ARGs for config** | `ARG PYTHON_VERSION=3.14` to make the base image version configurable without editing the Dockerfile. |
| **Layer caching optimization** | Copy `requirements.txt` before `COPY . .` (already done âœ…). Consider splitting pip install into core deps vs dev deps with a build ARG `--target=production`. |
| **`.dockerignore` audit** | Ensure `tests/`, `docs/`, `.git/`, `venv/`, `__pycache__/`, `*.md` are excluded from the build context to speed up `docker build`. |
| **Read-only root filesystem** | Run with `--read-only` and mount `/code/logs` and `/tmp` as tmpfs volumes. Limits blast radius if the container is compromised. |
| **Docker Compose** | Add a `docker-compose.yml` with `titanbay-app`, `titanbay-db` (PostgreSQL), optional `redis` for cache, and `pgadmin` for DB management â€” single `docker compose up` for the full stack. |

### Example: Docker Compose

```yaml
# docker-compose.yml
version: "3.9"
services:
  db:
    image: postgres:15-alpine
    environment:
      POSTGRES_USER: titanbay_user
      POSTGRES_PASSWORD: titanbay_password
      POSTGRES_DB: titanbay_db
    ports: ["5432:5432"]
    volumes: [pgdata:/var/lib/postgresql/data]
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U titanbay_user"]
      interval: 5s
      retries: 5

  app:
    build: .
    ports: ["8000:8000"]
    depends_on:
      db: { condition: service_healthy }
    environment:
      POSTGRES_USER: titanbay_user
      POSTGRES_PASSWORD: titanbay_password
      POSTGRES_SERVER: db
      POSTGRES_DB: titanbay_db

volumes:
  pgdata:
```

---

## CI/CD Pipeline â€” GitHub Actions

### Proposed Workflow

```yaml
# .github/workflows/ci.yml
name: CI

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:
  lint:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: { python-version: "3.14" }
      - run: pip install black isort flake8
      - run: black --check app/ tests/
      - run: isort --check-only app/ tests/
      - run: flake8 app/ tests/

  test:
    runs-on: ubuntu-latest
    needs: lint
    services:
      postgres:
        image: postgres:15-alpine
        env:
          POSTGRES_USER: test_user
          POSTGRES_PASSWORD: test_pass
          POSTGRES_DB: test_db
        ports: ["5432:5432"]
        options: >-
          --health-cmd pg_isready
          --health-interval 5s
          --health-retries 5
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: { python-version: "3.14" }
      - run: pip install -r requirements.txt
      - run: pytest --cov --cov-report=xml
        env:
          USE_SQLITE: "true"    # Unit tests use SQLite
      - uses: codecov/codecov-action@v4
        with: { files: coverage.xml }

  security:
    runs-on: ubuntu-latest
    needs: lint
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: { python-version: "3.14" }
      - run: pip install bandit pip-audit
      - run: bandit -r app/ -ll
      - run: pip-audit

  docker:
    runs-on: ubuntu-latest
    needs: test
    steps:
      - uses: actions/checkout@v4
      - uses: docker/setup-buildx-action@v3
      - uses: docker/build-push-action@v6
        with:
          context: .
          push: false
          tags: titanbay-service:${{ github.sha }}
          cache-from: type=gha
          cache-to: type=gha,mode=max
```

### Pipeline Enhancements

| Stage | Tool | Purpose |
| ----- | ---- | ------- |
| **Lint** | black, isort, flake8 | Formatting + import order + style enforcement |
| **Type check** | mypy --strict | Catch type errors before runtime |
| **Complexity** | radon + flake8-cognitive-complexity | Reject functions above a complexity threshold |
| **Unit tests** | pytest --cov | 160 tests, fail if coverage < 85% |
| **Integration tests** | pytest against PostgreSQL service | Real DB in CI via GitHub Actions services |
| **Security scan** | bandit + pip-audit | Vulnerability detection |
| **Docker build** | docker/build-push-action | Verify the image builds; push to registry on `main` |
| **Deploy** | ArgoCD / Kubernetes | Automatic deployment on `main` merge (future) |

### Branch Protection Rules

- Require all CI checks to pass before merge
- Require at least 1 code review approval
- Require linear history (rebase or squash merges)
- Auto-delete branches after merge

---

## Database & Data Layer

| Enhancement | Description |
| ----------- | ----------- |
| **Alembic migrations** | `alembic` is already in `requirements.txt` but not configured. Run `alembic init` and generate migration scripts for schema versioning. `create_all` works for demos but can't handle schema evolution (add/drop columns, rename tables). |
| **Soft deletes** | Add `deleted_at: Optional[datetime]` to models. Filter `WHERE deleted_at IS NULL` by default. Enables audit trails and undo without losing data. |
| **Audit log table** | Record every CREATE/UPDATE/DELETE with `user_id`, `action`, `old_value`, `new_value`, `timestamp`. Essential for financial compliance. |
| **Partitioning** | Partition `investments` by year (`investment_date`) for faster range queries as the table grows. |
| **Read replicas** | Route `GET` endpoints to a read replica for horizontal read scaling. |
| **Connection pool monitoring** | Expose pool stats (`pool.size()`, `pool.checkedout()`, `pool.overflow()`) on the `/health` endpoint. |

---

## API & Feature Enhancements

| Enhancement | Description |
| ----------- | ----------- |
| **API versioning via Accept header** | Support `Accept: application/vnd.titanbay.v2+json` alongside the URL prefix (`/api/v1`). |
| **PATCH support** | Add `PATCH /funds/{id}` for partial updates. Current `PUT /funds` requires the full resource body. |
| **Filtering & sorting** | `GET /funds?status=Fundraising&sort=-vintage_year` â€” add query params for field-level filtering and multi-column sorting. |
| **Cursor-based pagination** | Replace `skip/limit` with cursor pagination (`?after=<last_id>`) for stable results under concurrent writes. |
| **ETag / If-None-Match** | Return `ETag` headers on GET responses. Clients send `If-None-Match` to skip re-transfer of unchanged data (HTTP 304). |
| **Bulk endpoints** | `POST /funds/bulk` for batch creation. Reduces round-trips for bulk onboarding. |
| **Authentication & authorization** | JWT or OAuth2 with role-based access (admin, read-only, investor-scoped). Currently the API is fully open. |
| **Investor â†’ Investment relationship endpoint** | `GET /investors/{id}/investments` â€” list all investments for a specific investor across funds. |
| **Fund summary / analytics** | `GET /funds/{id}/summary` â€” return total committed capital, number of investors, percentage of target raised. |
| **OpenAPI spec export** | `GET /openapi.json` is auto-generated, but a versioned spec file checked into the repo enables contract testing and client SDK generation. |

---

## Observability & Monitoring

| Enhancement | Description |
| ----------- | ----------- |
| **Structured JSON logging** | Replace text logs with structured JSON (`structlog` or `python-json-logger`). Enables log aggregation in ELK/Datadog/Splunk. |
| **Prometheus metrics** | Expose `/metrics` with `prometheus-fastapi-instrumentator`: request latency histograms, error rates, active connections, circuit breaker state. |
| **Distributed tracing** | Integrate OpenTelemetry (`opentelemetry-instrumentation-fastapi`) to trace requests across services. Correlate with the existing `X-Request-ID` header. |
| **Alerting** | Define Grafana/PagerDuty alerts: P99 latency > 500ms, error rate > 1%, circuit breaker opens, DB pool exhaustion. |
| **Health check expansion** | Add dependency checks (Redis, external APIs) and readiness vs. liveness distinction for Kubernetes probes. |

---

## Security Hardening

| Enhancement | Description |
| ----------- | ----------- |
| **Authentication** | Add JWT bearer tokens via `fastapi-security` or OAuth2 password flow. Currently all endpoints are unauthenticated. |
| **Input sanitization** | While Pydantic handles type validation, add explicit sanitization for string fields to prevent stored XSS if data is rendered in a frontend. |
| **Rate limiting** | `slowapi` middleware to throttle requests per IP/API-key (e.g., 100 req/min for reads, 20 req/min for writes). |
| **HTTPS enforcement** | Add `TrustedHostMiddleware` and redirect HTTP â†’ HTTPS in production. |
| **Secrets management** | Move database credentials from environment variables to a secrets manager (AWS Secrets Manager, HashiCorp Vault, or Docker secrets). |
| **CORS tightening** | Replace the default `CORS_ORIGINS=*` with explicit allowed origins in production. |
| **Dependency pinning** | Pin all dependencies to exact versions in `requirements.txt` (e.g., `fastapi==0.115.6`) and use `pip-compile` for reproducible lockfiles. |
| **Container scanning** | Add Trivy or Snyk container scanning to CI to catch OS-level vulnerabilities in the Docker image. |

---

## Summary

The service **meets all 8 core and 2 bonus evaluation criteria**. The
enhancements above represent what a production deployment would add given
more time â€” they are not gaps for the scope of this take-home task.

| Category | Priority | Effort |
| -------- | -------- | ------ |
| Alembic migrations | ðŸ”´ High | 2 hours |
| GitHub Actions CI/CD | ðŸ”´ High | 2 hours |
| Repository integration tests | ðŸŸ¡ Medium | 3 hours |
| Docker Compose | ðŸŸ¡ Medium | 1 hour |
| Gunicorn multi-worker | ðŸŸ¡ Medium | 30 min |
| Cyclomatic complexity (radon) | ðŸŸ¡ Medium | 30 min |
| mypy strict type checking | ðŸŸ¡ Medium | 3 hours |
| Prometheus + Grafana | ðŸŸ¢ Low | 4 hours |
| Authentication (JWT) | ðŸŸ¢ Low | 4 hours |
| OpenTelemetry tracing | ðŸŸ¢ Low | 3 hours |
